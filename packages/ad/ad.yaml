changelog-type: ''
hash: 75e39c3ceadd19c3ee68003366b15372fbf2a2ff6831483a9719acefd3ae7d5a
synopsis: Automatic Differentiation
changelog: ''
all-versions:
- '0.12'
- '0.13'
- '0.15'
- '0.17'
- '0.18'
- '0.19'
- '0.20'
- '0.21'
- '0.22'
- '0.23'
- '0.24'
- '0.27'
- '0.28'
- '0.30.0'
- '0.31.0'
- '0.32.0'
- '0.33.0'
- '0.40'
- '0.40.1'
- '0.44.0'
- '0.44.1'
- '0.44.2'
- '0.44.3'
- '0.44.4'
- '0.45.0'
- '0.46.0'
- '0.46.1'
- '0.46.2'
- '0.47.0'
- '1.0.0'
- '1.0.1'
- '1.0.2'
- '1.0.3'
- '1.0.4'
- '1.0.5'
- '1.0.6'
- '1.1.0'
- '1.1.0.1'
- '1.1.1'
- '1.1.3'
- '1.2.0'
- '1.2.0.1'
- '1.2.0.2'
- '1.3'
- '1.3.0.1'
- '1.3.1'
- '1.4'
- '1.5'
- '1.5.0.1'
- '1.5.0.2'
- '3.0'
- '3.0.1'
- '3.1.1'
- '3.1.2'
- '3.1.3'
- '3.1.4'
- '3.2'
- '3.2.1'
- '3.2.2'
- '3.3.0.1'
- '3.3.1'
- '3.3.1.1'
- '3.4'
- '4.0'
- '4.0.0.1'
- '4.1'
- '4.2'
- '4.2.0.1'
- '4.2.1'
- '4.2.1.1'
- '4.2.2'
latest: '4.2.2'
description-type: haddock
description: ! 'Forward-, reverse- and mixed- mode automatic differentiation combinators
  with a common API.


  Type-level \"branding\" is used to both prevent the end user from confusing infinitesimals

  and to limit unsafe access to the implementation details of each Mode.


  Each mode has a separate module full of combinators.


  * @Numeric.AD.Mode.Forward@ provides basic forward-mode AD. It is good for computing
  simple derivatives.


  * @Numeric.AD.Mode.Reverse@ uses benign side-effects to compute reverse-mode AD.
  It is good for computing gradients in one pass. It generates a Wengert list (linear
  tape) using @Data.Reflection@.


  * @Numeric.AD.Mode.Kahn@ uses benign side-effects to compute reverse-mode AD. It
  is good for computing gradients in one pass. It generates a tree-like tape that
  needs to be topologically sorted in the end.


  * @Numeric.AD.Mode.Sparse@ computes a sparse forward-mode AD tower. It is good for
  higher derivatives or large numbers of outputs.


  * @Numeric.AD.Mode.Tower@ computes a dense forward-mode AD tower useful for higher
  derivatives of single input functions.


  * @Numeric.AD@ computes using whichever mode or combination thereof is suitable
  to each individual combinator.


  While not every mode can provide all operations, the following basic operations
  are supported, modified as

  appropriate by the suffixes below:


  * ''grad'' computes the gradient (partial derivatives) of a function at a point.


  * ''jacobian'' computes the Jacobian matrix of a function at a point.


  * ''diff'' computes the derivative of a function at a point.


  * ''du'' computes a directional derivative of a function at a point.


  * ''hessian'' computes the Hessian matrix (matrix of second partial derivatives)
  of a function at a point.


  The following suffixes alter the meanings of the functions above as follows:


  * @\''@ -- also return the answer


  * @With@ lets the user supply a function to blend the input with the output


  * @F@ is a version of the base function lifted to return a ''Traversable'' (or ''Functor'')
  result


  * @s@ means the function returns all higher derivatives in a list or f-branching
  ''Stream''


  * @T@ means the result is transposed with respect to the traditional formulation.


  * @0@ means that the resulting derivative list is padded with 0s at the end.'
