homepage: https://github.com/tonyday567/online
changelog-type: ''
hash: f41c6b8b568cc6d67a2434660440c55893d9295a607bb2cede3c3faff2413f14
test-bench-deps: {}
maintainer: tonyday567@gmail.com
synopsis: online statistics
changelog: ''
basic-deps:
  tdigest: -any
  numhask: -any
  base: ! '>=4.7 && <5'
  protolude: -any
  foldl: -any
  vector-algorithms: -any
  vector: -any
all-versions:
- '0.2.0'
author: Tony Day
latest: '0.2.0'
description-type: markdown
description: ! "[online](https://github.com/tonyday567/online)\n===\n\n[![Build Status](https://travis-ci.org/tonyday567/online.svg)](https://travis-ci.org/tonyday567/online)
  [![Hackage](https://img.shields.io/hackage/v/online.svg)](https://hackage.haskell.org/package/online)
  [![lts](https://www.stackage.org/package/online/badge/lts)](http://stackage.org/lts/package/online)
  [![nightly](https://www.stackage.org/package/online/badge/nightly)](http://stackage.org/nightly/package/online)\n\nonline
  turns a statistic (in haskell this can usually be thought of as a fold of a foldable)
  into an online algorithm.\n\nmotivation\n===\n\nImagine a data stream, like an ordered
  indexed container or a\ntime-series of measurements. An exponential moving average
  can be\ncalculated as a repeated iteration over a stream of xs:\n\n$$ ema_t = ema_{t-1}
  * 0.9 + x_t * 0.1 $$\n\nThe 0.1 is akin to the learning rate in machine learning,
  or 0.9 can be\nthought of as a decaying or a rate of forgetting. An exponential
  moving\naverage learns about what the value of x has been lately, where lately\nis,
  on average, about 1/0.1 = 10 x's ago. All very neat.\n\nThe first bit of neat is
  speed. There's 2 times and a plus. The next is\nspace: an ema is representing the
  recent xs in a size as big as a single\nx. Compare that with a simple moving average
  where you have to keep the\nhistory of the last n xs around to keep up (just try
  it).\n\nIt's so neat, it's probably a viable monoidal category all by itself.\n\nonline\n======\n\nHaskell
  allows us to abstract the compound ideas in an ema and create\npolymorphic routines
  over a wide variety of statistics, so that they all\nretain these properties of
  speed, space and rigour.\n\n    av xs = L.fold (online identity (.* 0.9)) xs\n    --
  av [0..10] == 6.030559401413827\n    -- av [0..100] == 91.00241448887785\n\n`online
  identity (.* 0.9)` is how you express an ema with a decay rate\nof 0.9.\n\nonline
  works for any statistic. Here's the construction of standard\ndeviation using applicative
  style:\n\n    std :: Double -> L.Fold Double Double\n    std r = (\\s ss -> sqrt
  (ss - s**2)) <$> ma r <*> sqma r\n      where\n        ma r = online identity (.*r)\n
  \       sqma r = online (**2) (.*r)\n"
license-name: BSD3
