homepage: https://github.com/haskell-works/hw-kafka-client
changelog-type: ''
hash: 41f4eb2d80563360c8a99412d5c5d7405e7cc2d4b5673c320a2f172d12d01ae2
test-bench-deps:
  either: -any
  bytestring: -any
  base: ! '>=4.6 && <5'
  hspec: -any
  monad-loops: -any
  containers: -any
  bifunctors: -any
  regex-posix: -any
  hw-kafka-client: -any
maintainer: Alexey Raga <alexey.raga@gmail.com>
synopsis: Kafka bindings for Haskell
changelog: ''
basic-deps:
  bytestring: -any
  unix: -any
  base: ! '>=4.6 && <5'
  containers: -any
  bifunctors: -any
  hw-kafka-client: -any
  transformers: -any
  temporary: -any
all-versions:
- '1.0.0'
- '1.1.0'
author: Alexey Raga <alexey.raga@gmail.com>
latest: '1.1.0'
description-type: markdown
description: ! "# kafka-client  \n[![Circle CI](https://circleci.com/gh/haskell-works/kafka-client.svg?style=svg&circle-token=5f3ada2650dd600bc0fd4787143024867b2afc4e)](https://circleci.com/gh/haskell-works/kafka-client)\n\nKafka
  bindings for Haskell backed by the\n[librdkafka C module](https://github.com/edenhill/librdkafka).\n\n##
  Credits\nThis project is inspired by [Haskakafka](https://github.com/cosbynator/haskakafka)\nwhich
  unfortunately doesn't seem to be actively maintained.\n\n## Ecosystem\nHaskellWorks
  Kafka ecosystem is described here: https://github.com/haskell-works/hw-kafka\n\n#
  Consumer\nHigh level consumers are supported by `librdkafka` starting from version
  0.9.  \nHigh-level consumers provide an abstraction for consuming messages from
  multiple\npartitions and topics. They are also address scalability (up to a number
  of partitions)\nby providing automatic rebalancing functionality. When a new consumer
  joins a consumer\ngroup the set of consumers attempt to \"rebalance\" the load to
  assign partitions to each consumer.\n\n### Example:\nA working consumer example
  can be found here: [ConsumerExample.hs](example/ConsumerExample.hs)\n\n```Haskell\nimport
  Data.Monoid ((<>))\nimport Kafka\nimport Kafka.Consumer\n\n-- Global consumer properties\nconsumerProps
  :: ConsumerProperties\nconsumerProps = consumerBrokersList [BrokerAddress \"localhost:9092\"]\n
  \            <> groupId (ConsumerGroupId \"consumer_example_group\")\n             <>
  noAutoCommit\n             <> consumerDebug [DebugAll]\n\n-- Subscription to topics\nconsumerSub
  :: Subscription\nconsumerSub = topics [TopicName \"kafka-client-example-topic\"]\n
  \          <> offsetReset Earliest\n\n-- Running an example\nrunConsumerExample
  :: IO ()\nrunConsumerExample = do\n    res <- runConsumer consumerProps consumerSub
  processMessages\n    print res\n\n-------------------------------------------------------------------\nprocessMessages
  :: KafkaConsumer -> IO (Either KafkaError ())\nprocessMessages kafka = do\n    mapM_
  (\\_ -> do\n                   msg1 <- pollMessage kafka (Timeout 1000)\n                   putStrLn
  $ \"Message: \" <> show msg1\n                   err <- commitAllOffsets kafka OffsetCommit\n
  \                  putStrLn $ \"Offsets: \" <> maybe \"Committed.\" show err\n          )
  [0 .. 10]\n    return $ Right ()\n```\n\n# Producer\n`kafka-client` producer supports
  sending messages to multiple topics.\nTarget topic name is a part of each message
  that is to be sent by `produceMessage`.\n\nA working producer example can be found
  here: [ProducerExample.hs](example/ProducerExample.hs)\n\n### Example\n\n```Haskell\nimport
  Control.Monad (forM_)\nimport Kafka\nimport Kafka.Producer\n\n-- Global producer
  properties\nproducerProps :: ProducerProperties\nproducerProps = producerBrokersList
  [BrokerAddress \"localhost:9092\"]\n\n-- Topic to send messages to\ntargetTopic
  :: TopicName\ntargetTopic = TopicName \"kafka-client-example-topic\"\n\n-- Run an
  example\nrunProducerExample :: IO ()\nrunProducerExample = do\n    res <- runProducer
  producerProps sendMessages\n    print res\n\nsendMessages :: KafkaProducer -> IO
  (Either KafkaError ())\nsendMessages prod = do\n  err1 <- produceMessage prod ProducerRecord\n
  \                               { prTopic = targetTopic\n                                ,
  prPartition = UnassignedPartition\n                                , prKey = Nothing\n
  \                               , prValue = Just \"test from producer\"\n                                }\n
  \ forM_ err1 print\n\n  err2 <- produceMessage prod ProducerRecord\n                                {
  prTopic = targetTopic\n                                , prPartition = UnassignedPartition\n
  \                               , prKey = Just \"key\"\n                                ,
  prValue = Just \"test from producer (with key)\"\n                                }\n
  \ forM_ err2 print\n\n  return $ Right ()\n```\n\n# Installation\n\n## Installing
  librdkafka\n\nAlthough `librdkafka` is available on many platforms, most of\nthe
  distribution packages are too old to support `kafka-client`.\nAs such, we suggest
  you install from the source:\n\n    git clone https://github.com/edenhill/librdkafka\n
  \   cd librdkafka\n    ./configure\n    make && sudo make install\n\nSometimes it
  is helpful to specify openssl includes explicitly:\n\n    LDFLAGS=-L/usr/local/opt/openssl/lib
  CPPFLAGS=-I/usr/local/opt/openssl/include ./configure\n\n## Installing Kafka\n\nThe
  full Kafka guide is at http://kafka.apache.org/documentation.html#quickstart\n\nAlternatively
  `docker-compose` can be used to run Kafka locally inside a Docker container.\nTo
  run Kafka inside Docker:\n\n```\n$ docker-compose up\n```\n"
license-name: MIT
