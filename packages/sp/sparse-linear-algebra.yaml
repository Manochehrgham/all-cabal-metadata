homepage: https://github.com/ocramz/sparse-linear-algebra
changelog-type: ''
hash: 80f1a2c4a499df0fcf4ab8c6732cbb1255037f84307c91b034fe5ab8ab28b201
test-bench-deps:
  mwc-random: -any
  base: -any
  hspec: -any
  criterion: -any
  containers: -any
  mtl: ! '>=2.2.1'
  sparse-linear-algebra: -any
  primitive: ! '>=0.6.1.0'
maintainer: zocca.marco gmail
synopsis: Numerical computation in native Haskell
changelog: ''
basic-deps:
  mwc-random: -any
  base: ! '>=4.7 && <5'
  hspec: -any
  containers: -any
  mtl: ! '>=2.2.1'
  QuickCheck: -any
  primitive: ! '>=0.6.1.0'
  vector: -any
all-versions:
- '0.1.0.0'
- '0.1.0.1'
- '0.1.0.2'
- '0.1.0.3'
- '0.2.0.0'
- '0.2.0.1'
- '0.2.0.2'
- '0.2.0.3'
- '0.2.0.4'
- '0.2.0.5'
- '0.2.0.7'
- '0.2.0.8'
- '0.2.0.9'
- '0.2.1.0'
- '0.2.1.1'
- '0.2.2.0'
author: Marco Zocca
latest: '0.2.2.0'
description-type: markdown
description: ! "# sparse-linear-algebra\n\nNumerical computation in native Haskell\n\nTravisCI
  : [![Build Status](https://travis-ci.org/ocramz/sparse-linear-algebra.png)](https://travis-ci.org/ocramz/sparse-linear-algebra)\n\nThis
  library provides common numerical analysis functionality, without requiring any
  external bindings. It is not optimized for performance (yet), but it serves as an
  experimental platform for scientific computation in a purely functional setting.\n\nContents
  :\n\n* Iterative linear solvers (`linSolve`)\n\n    * Generalized Minimal Residual
  (GMRES) (non-Hermitian systems) \n\n    * BiConjugate Gradient (BCG)\n\n    * Conjugate
  Gradient Squared (CGS)\n\n    * BiConjugate Gradient Stabilized (BiCGSTAB) (non-Hermitian
  systems)\n\n    * Transpose-Free Quasi-Minimal Residual (TFQMR)\n\n* Direct linear
  solvers\n\n    * LU-based (`luSolve`)\n\n* Matrix factorization algorithms\n\n    *
  QR (`qr`)\n\n    * LU (`lu`)\n\n    * Cholesky (`chol`)\n\n* Eigenvalue algorithms\n\n
  \   * Arnoldi iteration (`arnoldi`)\n\n    * QR (`eigsQR`)\n\n    * Rayleigh quotient
  iteration (`eigRayleigh`)\n\n* Utilities : Vector and matrix norms, matrix condition
  number, Givens rotation, Householder reflection\n\n* Predicates : Matrix orthogonality
  test (A^T A ~= I)\n\n\n---------\n\n## Examples\n\nThe module `Numeric.LinearAlgebra.Sparse`
  contains the user interface.\n\n### Creation of sparse data\n\nThe `fromListSM`
  function creates a sparse matrix from an array of its entries we use :\n\n    fromListSM
  :: Foldable t => (Int, Int) -> t (IxRow, IxCol, a) -> SpMatrix a\n\ne.g.\n\n    >
  amat = fromListSM (3,3) [(0,0,2),(1,0,4),(1,1,3),(1,2,2),(2,2,5)]\n\nand similarly\n\n
  \   fromListSV :: Int -> [(Int, a)] -> SpVector a\n\ncan be used to create sparse
  vectors.\nAlternatively, the user can copy the contents of a list to a (dense) SpVector
  using\n\n    fromListDenseSV :: Int -> [a] -> SpVector a\n\n\n### Displaying sparse
  data\n\nBoth sparse vectors and matrices can be pretty-printed using `prd`:\n\n
  \   > prd amat\n    ( 3 rows, 3 columns ) , 5 NZ ( sparsity 0.5555555555555556 )\n\n
  \   [2,0,0]\n    [4,3,2]\n    [0,0,5]\n\nThe zeros are just added at printing time;
  sparse vectors and matrices should only contain non-zero entries.\n\n### Matrix
  operations\n\nThere are a few common matrix factorizations available; in the following
  example we compute the LU factorization of a matrix and verify it with the matrix-matrix
  product `##`  :\n\n    > (l, u) = lu amat\n    > prd $ l ## u\n    ( 3 rows, 3 columns
  ) , 9 NZ ( sparsity 1.0 )\n\n    [2.0,0.0,0.0]\n    [4.0,3.0,2.0]\n    [0.0,0.0,5.0]\n\nNotice
  that the result is _dense_, i.e. certain entries are numerically zero but have been
  inserted into the result along with all the others (thus taking up memory!).\nTo
  preserve sparsity, we can use a sparsifying matrix-matrix product `#~#`, which filters
  out all the elements x for which `|x| <= eps`, where `eps` (defined in `Numeric.Eps`)
  depends on the numerical type used (e.g. it is 10^-6 for `Float`s and 10^-12 for
  `Double`s).\n\n    > prd $ l #~# u\n    ( 3 rows, 3 columns ) , 5 NZ ( sparsity
  0.5555555555555556 )\n\n    [2.0,0.0,0.0]\n    [4.0,3.0,2.0]\n    [0.0,0.0,5.0]\n\nA
  matrix is transposed using `transposeSM`.\n\nSometimes we need to compute matrix-matrix
  transpose products, which is why the library offers the infix operators `#^#` (M^T
  N) and `##^` (M N^T):\n\n    > amat' = amat #^# amat\n    > prd amat'\n    ( 3 rows,
  3 columns ) , 9 NZ ( sparsity 1.0 )\n\n    [20.0,12.0,8.0]\n    [12.0,9.0,6.0]\n
  \   [8.0,6.0,29.0]\n\n    > l = chol amat'\n    > prd $ l ##^ l\n    ( 3 rows, 3
  columns ) , 9 NZ ( sparsity 1.0 )\n\n    [20.000000000000004,12.0,8.0]\n    [12.0,9.0,10.8]\n
  \   [8.0,10.8,29.0]\n\nIn the above example we have also shown the Cholesky decomposition
  (M = L L^T where L is a lower-triangular matrix), which is only possible for symmetric
  positive-definite matrices.\n\n### Linear systems\n\nLarge sparse linear systems
  are best solved with iterative methods. `sparse-linear-algebra` provides a selection
  of these via the `linSolve` function, or alternatively `<\\>` (which uses GMRES
  as default solver method) :\n\n    > b = fromListDenseSV 3 [3,2,5]\n    > x = amat
  <\\> b\n    > prd x\n    ( 3 elements ) ,  3 NZ ( sparsity 1.0 )\n\n    [1.4999999999999998,-1.9999999999999998,0.9999999999999998]\n\nThe
  result can be verified by computing the matrix-vector action `amat #> x`, which
  should (ideally) be very close to the right-hand side `b` :\n\n    > prd $ amat
  #> x\n    ( 3 elements ) ,  3 NZ ( sparsity 1.0 )\n\n    [2.9999999999999996,1.9999999999999996,4.999999999999999]\n\nThe
  library also provides a forward-backward substitution solver (`luSolve`) based on
  a triangular factorization of the system matrix (usually LU). This should be the
  preferred for solving smaller, dense systems. Using the data defined above we can
  cross-verify the two solution methods:\n\n    > x' = luSolve l u b\n    > prd x'\n\n
  \   ( 3 elements ) ,  3 NZ ( sparsity 1.0 )\n\n    [1.5,-2.0,1.0]\n\n\n\n\n\n----------\n\nThis
  is also an experiment in principled scientific programming :\n\n* set the stage
  by declaring typeclasses and some useful generic operations (normed linear vector
  spaces, i.e. finite-dimensional spaces equipped with an inner product that induces
  a distance function),\n\n* define appropriate data structures, and how they relate
  to those properties (sparse vectors and matrices, defined internally via `Data.IntMap`,
  are made instances of the VectorSpace and Additive classes respectively). This allows
  to decouple the algorithms from the actual implementation of the backend,\n\n* implement
  the algorithms, following 1:1 the textbook [1, 2] \n\n\n## License\n\nGPL3, see
  LICENSE\n\n## Credits\n\nInspired by\n\n* `linear` : https://hackage.haskell.org/package/linear\n*
  `sparse-lin-alg` : https://github.com/laughedelic/sparse-lin-alg\n\n## References\n\n[1]
  : Y. Saad, Iterative Methods for Sparse Linear Systems, 2nd ed., 2000\n\n[2] : L.
  N. Trefethen, D. Bau, Numerical Linear Algebra, SIAM, 1997"
license-name: GPL-3
