homepage: ''
changelog-type: ''
hash: 95a429d0922bf0e06eac0af25994c320516796dcb44d6c392413c79d5fffd8d8
test-bench-deps: {}
maintainer: alp.mestanogullari@tweag.io
synopsis: Distributed Apache Spark applications in Haskell
changelog: ''
basic-deps:
  zip-archive: ! '>=0.2'
  bytestring: ! '>=0.10'
  base: ! '>=4.8 && <5'
  jni: ! '>=0.1'
  text: ! '>=1.2'
  filepath: ! '>=1.4'
  process: ! '>=1.2'
  jvm: ! '>=0.1'
  singletons: ! '>=2.0'
  distributed-closure: ! '>=0.3'
  binary: ! '>=0.7'
  regex-tdfa: ! '>=1.2'
  sparkle: -any
  vector: ! '>=0.11'
all-versions:
- '0.1'
- '0.1.0.1'
- '0.2'
- '0.3'
author: Tweag I/O
latest: '0.3'
description-type: markdown
description: ! "# Sparkle: Apache Spark applications in Haskell\n\n[![Circle CI](https://circleci.com/gh/tweag/sparkle.svg?style=svg)](https://circleci.com/gh/tweag/sparkle)\n\n*Sparkle
  [spär′kəl]:* a library for writing resilient analytics\napplications in Haskell
  that scale to thousands of nodes, using\n[Spark][spark] and the rest of the Apache
  ecosystem under the hood.\nSee [this blog post][hello-sparkle] for the details.\n\n**This
  is an early tech preview, not production ready.**\n\n[spark]: http://spark.apache.org/\n[hello-sparkle]:
  http://blog.tweag.io/posts/2016-02-25-hello-sparkle.html\n\n## Getting started\n\nThe
  tl;dr using the `hello` app as an example on your local machine:\n\n```\n$ stack
  build hello\n$ stack exec -- sparkle package sparkle-example-hello\n$ stack exec
  -- spark-submit --master 'local[1]' sparkle-example-hello.jar\n```\n\n**Requirements:**\n*
  the [Stack][stack] build tool (version 1.2 or above);\n* either, the [Nix][nix]
  package manager,\n* or, OpenJDK, Gradle and Spark (version 1.6) installed from your
  distro.\n\nTo run a Spark application the process is as follows:\n\n1. **create**
  an application in the `apps/` folder, in-repo or as\n   a submodule;\n1. **add**
  your app to `stack.yaml`;\n1. **build** the app;\n1. **package** your app into a
  deployable JAR container;\n1. **submit** it to a local or cluster deployment of
  Spark.\n\n**If you run into issues, read the Troubleshooting section below\n  first.**\n\nTo
  build:\n\n```\n$ stack build\n```\n\nYou can optionally get Stack to download Spark
  and Gradle in a local\nsandbox (using [Nix][nix]) for good build results reproducibility.\n**This
  is the recommended way to build sparkle.** Alternatively,\nyou'll need these installed
  through your OS distribution's package\nmanager for the next steps (and you'll need
  to tell Stack how to find\nthe JVM header files and shared libraries).\n\nTo use
  Nix, set the following in your `~/.stack/config.yaml` (or pass\n`--nix` to all Stack
  commands, see the [Stack manual][stack-nix] for\nmore):\n\n```yaml\nnix:\n  enable:
  true\n```\n\nTo package your app as a JAR directly consumable by Spark:\n\n```\n$
  stack exec -- sparkle package <app-executable-name>\n```\n\nFinally, to run your
  application, for example locally:\n\n```\n$ stack exec -- spark-submit --master
  'local[1]' <app-executable-name>.jar\n```\n\nThe `<app-executable-name>` is any
  executable name as given in the\n`.cabal` file for your app. See apps in the [apps/](apps/)
  folder for\nexamples.\n\nSee [here][spark-submit] for other options, including launching\na
  [whole cluster from scratch on EC2][spark-ec2]. This\n[blog post][tweag-blog-haskell-paas]
  shows you how to get started on\nthe [Databricks hosted platform][databricks] and
  on\n[Amazon's Elastic MapReduce][aws-emr].\n\n[stack]: https://github.com/commercialhaskell/stack\n[stack-nix]:
  https://docs.haskellstack.org/en/stable/nix_integration/#configuration\n[spark-submit]:
  http://spark.apache.org/docs/1.6.2/submitting-applications.html\n[spark-ec2]: http://spark.apache.org/docs/1.6.2/ec2-scripts.html\n[nix]:
  http://nixos.org/nix\n[tweag-blog-haskell-paas]: http://blog.tweag.io/posts/2016-06-20-haskell-compute-paas-with-sparkle.html\n[databricks]:
  https://databricks.com/\n[aws-emr]: https://aws.amazon.com/emr/\n\n### Non-Linux
  OSes\n\nSparkle is not currently supported on non-linux OSes, e.g. Mac OS X or Windows.
  If you want to build and use it from a machine using\nsuch an OS, you can use the
  provided `Dockerfile` and build everything in [docker](http://docker.io):\n\n```\n$
  docker build -t sparkle .\n```\n\nwill create an image named `sparkle` containing
  everything that's\nneeded to build sparkle and Spark applications: Stack, Java 8,
  Gradle.\n\nThis image can be used to build sparkle then package and run applications:\n\n```\n#
  stack --docker --docker-image sparkle build\n...\n```\n\nNote that you will need
  to edit the `stack.yaml` file to point to\ninclude directories and libraries for
  building the C bits that\ninteract with the JVM:\n\n```\nextra-include-dirs:\n  -
  '/usr/lib/jvm/java-1.8.0-openjdk-amd64/include'\n  - '/usr/lib/jvm/java-1.8.0-openjdk-amd64/include/linux'\nextra-lib-dirs:\n
  \ - '/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64/server/'\n```\n\nOnce everything
  is built you can generate a spark package and run it using `sparkle`'s command-line:\n\n```\n#
  stack --docker --docker-image sparkle exec sparkle package sparkle-example-hello\n```\n\n##
  How it works\n\nsparkle is a tool for creating self-contained Spark applications
  in\nHaskell. Spark applications are typically distributed as JAR files, so\nthat's
  what sparkle creates. We embed Haskell native object code as\ncompiled by GHC in
  these JAR files, along with any shared library\nrequired by this object code to
  run. Spark dynamically loads this\nobject code into its address space at runtime
  and interacts with it\nvia the Java Native Interface (JNI).\n\n## Troubleshooting\n\n###
  `jvm` library or header files not found\n\nYou'll need to tell Stack where to find
  your local JVM installation.\nSomething like the following in your `~/.stack/config.yaml`
  should do\nthe trick, but check that the paths match up what's on your system:\n\n```\nextra-include-dirs:
  [/usr/lib/jvm/java-7-openjdk-amd64/include]\nextra-lib-dirs: [/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/amd64/server]\n```\n\nOr
  use `--nix`: since it won't use your globally installed JDK, it\nwill have no trouble
  finding its own locally installed one.\n\n### Can't build sparkle on OS X\n\nOS
  X is not a supported platform for now. There are several issues to\nmake sparkle
  work on OS X, tracked\n[in this ticket](https://github.com/tweag/sparkle/issues/12).\n\n###
  Gradle <= 2.12 incompatible with JDK 9\n\nIf you're using JDK 9, note that you'll
  need to either downgrade to\nJDK 8 or update your Gradle version, since Gradle versions
  up to and\nincluding 2.12 are not compatible with JDK 9.\n\n## License\n\nCopyright
  (c) 2015-2016 EURL Tweag.\n\nAll rights reserved.\n\nSparkle is free software, and
  may be redistributed under the terms\nspecified in the [LICENSE](LICENSE) file.\n\n##
  About\n\n![Tweag I/O](http://i.imgur.com/0HK8X4y.png)\n\nSparkle is maintained by
  [Tweag I/O](http://tweag.io/).\n\nHave questions? Need help? Tweet at\n[@tweagio](http://twitter.com/tweagio).\n"
license-name: BSD3
