homepage: http://www.aivikasoft.com
changelog-type: markdown
hash: f3319aa1bc1c8c8c5185eadca65398fe04f2c6935ed85e91e0d4c5191c96ac20
test-bench-deps: {}
maintainer: David Sorokin <david.sorokin@gmail.com>
synopsis: Parallel distributed discrete event simulation module for the Aivika library
changelog: ! "\nVersion 0.7.1\n-----\n\n* Added the time server and logical process
  strategies to shutdown the cluster\n  in case of failure by the specified timeout
  intervals.\n\nVersion 0.7\n-----\n\n* Fixed the use of the LP abbreviation.\n\nVersion
  0.6\n-----\n\n* Using the mwc-random package for generating random numbers by default.\n\nVersion
  0.5.1\n-----\n\n* Added functions expectEvent and expectProcess.\n\n* Added the
  Guard module.\n\nVersion 0.5\n-----\n\n* Added an ability to restore the distributed
  simulation after temporary connection errors.\n\n* Better finalisation of the distributed
  simulation.\n\n* Implemented lazy references.\n\nVersion 0.3\n-----\n\n* Started
  using Samadi's algorithm to synchronize the global virtual time.\n\n* The logical
  processes must call registerDIO to connect to the time server.\n\n* Increased the
  default synchronization time-out and delay.\n\n* Increased the default log size
  threshold.\n"
basic-deps:
  exceptions: ! '>=0.8.0.2'
  mwc-random: ! '>=0.13.0.0'
  stm: ! '>=2.4.2'
  base: ! '>=4.6.0.0 && <6'
  time: ! '>=1.5.0.1'
  distributed-process: ! '>=0.6.1'
  aivika: ! '>=5.2'
  aivika-transformers: ! '>=5.2'
  containers: ! '>=0.4.0.0'
  binary: ! '>=0.6.4.0'
  mtl: ! '>=2.1.1'
  random: ! '>=1.0.0.3'
all-versions:
- '0.1'
- '0.1.1'
- '0.1.3'
- '0.2'
- '0.3'
- '0.3.1'
- '0.5'
- '0.6'
- '0.7'
- '0.7.1.1'
author: David Sorokin
latest: '0.7.1.1'
description-type: haddock
description: ! 'This package extends the aivika-transformers [1] package and allows
  running parallel distributed simulations.

  It uses an optimistic strategy known as the Time Warp method. To synchronize the
  global virtual time,

  it uses Samadi''s algorithm.


  Moreover, this package uses the author''s modification that allows recovering the
  distributed

  simulation after temporary connection errors whenever possible. For that, you have
  to enable explicitly

  the recovering mode and enable monitoring all logical processes including the specialized
  Time Server process

  as it is shown in one of the test examples included in the distribution.


  With the recovering mode enabled, you can try to build a distributed simulation
  using ordinary computers connected

  via the ordinary net. For example, such a distributed model could even consist of
  computers located in different

  continents of the Earth, where the computers could be connected through the Internet.
  Here the most exciting thing

  is that this is the optimistic distributed simulation with possible rollbacks. It
  is assumed that optimistic methods

  tend to better support the parallelism inherited in the models.


  You may test the distributed simulation using your own laptop only, although the
  package is still destined to be

  used with a multi-core computer, or computers connected in the distributed cluster.


  There are additional packages that allow you to run the distributed simulation experiments
  by

  the Monte-Carlo method. They allow you to save the simulation results in SQL databases
  and then generate a report

  or a set of reports consisting of HTML pages with charts, histograms, links to CSV
  tables, summary statistics etc.

  Please consult the AivikaSoft [3] website for more details.


  Regarding the speed of simulation, the rough estimations are as follows. The distributed
  simulation module is slower up to

  6-9 times in comparison with the sequential aivika [2] simulation library using
  the equivalent sequential models.

  Note that you can run up to 7 parallel logical processes on a single 8-core processor
  computer and run the Time Server

  process too. On a 36-core processor, you can launch up to 35 logical processes simultaneously.


  So, this estimation seems to be quite good. At the same time, the message passing
  between the logical processes can

  dramatically decrease the speed of distributed simulation, especially if they cause
  rollbacks. Thus, much depends on

  the distributed model itself.


  \[1] <http://hackage.haskell.org/package/aivika-transformers>


  \[2] <http://hackage.haskell.org/package/aivika>


  \[3] <http://www.aivikasoft.com>

'
license-name: BSD3
