homepage: ''
changelog-type: ''
hash: b2708a2f10252d685908e113ecbbe3399f2f843501f31ec2b521ff59090423c9
test-bench-deps: {}
maintainer: kai@kzhang.org
synopsis: Scientific workflow management system
changelog: ''
basic-deps:
  cereal: -any
  shelly: -any
  bytestring: -any
  split: -any
  base: ! '>=4.0 && <5.0'
  sqlite-simple: -any
  text: -any
  executable-path: -any
  rainbow: -any
  graphviz: -any
  containers: -any
  lens: ! '>=4.0'
  fgl: -any
  mtl: -any
  lifted-async: -any
  transformers: -any
  optparse-applicative: -any
  th-lift: -any
  template-haskell: -any
  yaml: -any
  directory: -any
all-versions:
- '0.1.0'
- '0.2.0'
- '0.3.0'
- '0.4.0'
- '0.4.1'
- '0.5.0'
- '0.5.1'
author: Kai Zhang
latest: '0.5.1'
description-type: markdown
description: ! "Scientific workflow management system\n=====================================\n\nIntroduction\n------------\n\nSciFlow
  is a workflow management system for working with big data pipelines locally\nor
  in a grid computing system.\n\nMost scientific computing pipelines are composed
  of many computational steps, and each of them involves heavy computation and IO
  operations. A workflow management system can\nhelp user design complex computing
  patterns and track the states of computation.\nThe ability to recover from failures
  is crucial in large pipelines as they usually\ntake days or weeks to finish.\n\nFeatures:\n\n1.
  Easy to use: A simple and flexible way to specify computational pipelines in Haskell.\n\n2.
  Automatic Checkpointing: The result of each intermediate step is stored, allowing
  easy restart upon failures.\n\n3. Parallelism and grid computing support: Independent
  computational steps will run concurrently. And users can decide whether to run steps
  locally or on remote compute nodes in a grid system.\n\nHere is a simple example.
  (Since we use template haskell, we need to divide this small program into two files.)\n\n```haskell\n---------------------------------------------------\n--
  File 1: MyModule.hs\n---------------------------------------------------\n{-# LANGUAGE
  OverloadedStrings #-}\n{-# LANGUAGE TemplateHaskell #-}\nmodule Functions\n    (builder)
  where\n\nimport Control.Lens ((^.), (.=))\nimport qualified Data.Text as T\nimport
  Shelly hiding (FilePath)\nimport Text.Printf (printf)\n\nimport Scientific.Workflow\n\ncreate
  :: () -> IO FilePath\ncreate _ = do\n    writeFile \"hello.txt\" \"hello world\"\n
  \   return \"hello.txt\"\n\ncountWords :: FilePath -> IO Int\ncountWords fl = do\n
  \   content <- readFile fl\n    return $ length $ words content\n\ncountChars ::
  FilePath -> IO Int\ncountChars fl = do\n    content <- readFile fl\n    return $
  sum $ map length $ words content\n\noutput :: (Int, Int) -> IO Bool\noutput (ws,
  cs) = do\n    putStrLn $ printf \"Number of words: %d\" ws\n    putStrLn $ printf
  \"Number of characters: %d\" cs\n    return True\n\ncleanUp :: (Bool, FilePath)
  -> IO ()\ncleanUp (toBeRemoved, fl) = if toBeRemoved\n    then shelly $ rm $ fromText
  $ T.pack fl\n    else return ()\n\n-- builder monad\nbuilder :: Builder ()\nbuilder
  = do\n    node \"step0\" 'create $ label .= \"write something to a file\"\n    node
  \"step1\" 'countWords $ label .= \"word count\"\n    node \"step2\" 'countChars
  $ label .= \"character count\"\n    node \"step3\" 'output $ label .= \"print\"\n
  \   node \"step4\" 'cleanUp $ label .= \"remove the file\"\n\n    [\"step0\"] ~>
  \"step1\"\n    [\"step0\"] ~> \"step2\"\n    [\"step1\", \"step2\"] ~> \"step3\"\n
  \   [\"step3\", \"step0\"] ~> \"step4\"\n\n---------------------------------------------------\n--
  File 2: main.hs\n---------------------------------------------------\n{-# LANGUAGE
  TemplateHaskell #-}\n\nimport qualified Functions as F\nimport Scientific.Workflow.Main\n\ndefaultMain
  F.builder\n```\n\nUse `ghc main.hs -threaded` to compile the program. And type `./main
  --help` to\nsee available commands. For example, the workflow can be visualized
  by running\n`./main view | dot -Tpng > example.png`, as shown below.\n\n![example](example.png)\n\nTo
  run the workflow, simply type `./main run`. The program will create a sqlite database
  to store intermediate results. If being terminated prematurely, the program will
  use the saved data to continue from the last step.\n\nTo enable grid compute engine
  support, you need to have DRMAA C library installed\nand compile the SciFlow with
  `-f sge` flag. Use `./main run --remote` to submit jobs\nto remote machines.\n"
license-name: MIT
