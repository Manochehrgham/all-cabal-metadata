homepage: ''
changelog-type: ''
hash: 98b3845ee71b76fbdca423109f69aa0b8e386203269d1c708b22709ec0db9c33
test-bench-deps:
  base: ! '>=4.6 && <5'
  time: -any
  tasty-hunit: -any
  concurrent-machines: -any
  transformers: -any
  tasty: -any
  machines: -any
maintainer: acowley@gmail.com
synopsis: Concurrent networked stream transducers
changelog: ''
basic-deps:
  base: ! '>=4.6 && <5'
  time: ! '>=1.4 && <1.6'
  monad-control: ! '>=1.0 && <1.1'
  async: ! '>=2.0.1 && <2.1'
  semigroups: ! '>=0.8 && <0.17'
  containers: ! '>=0.5 && <0.6'
  lifted-async: ! '>=0.1 && <0.8'
  transformers-base: ! '>=0.4 && <0.5'
  transformers: ! '>=0.4 && <0.5'
  machines: ! '>=0.5 && <0.6'
all-versions:
- '0.1.0.0'
- '0.1.0.1'
author: Anthony Cowley
latest: '0.1.0.1'
description-type: haddock
description: ! 'A simple use-case for this library is to run the stages

  of a pipelined streaming computation concurrently. If

  data is streaming through multiple processing stages, you

  might build a machine like


  @

  step1 >~> step2 >~> step3

  @


  The @>~>@ operator connects the machines on

  either side with a one-element buffer. This means that

  data is pulled from upstream sources eagerly (perhaps

  pulling one more value than will be consumed by

  downstream), but it also means that each stage can be

  working simultaneously, increasing throughput of the

  entire pipeline.


  A few small examples are available in the @examples@

  directory of the source repository.'
license-name: BSD3
