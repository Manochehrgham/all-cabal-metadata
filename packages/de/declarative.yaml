homepage: http://github.com/jtobin/declarative
changelog-type: ''
hash: 00a8725098c84ef8e36932883b56227231539f14f564d3251f04bda3da36e302
test-bench-deps:
  declarative: -any
  base: <5
  mwc-probability: ! '>=1.0.1'
maintainer: jared@jtobin.ca
synopsis: DIY Markov Chains.
changelog: ''
basic-deps:
  base: <5
  hasty-hamiltonian: ! '>=1.1.1'
  mcmc-types: ! '>=1.0.1'
  lens: ! '>=4 && <5'
  pipes: ! '>=4 && <5'
  transformers: -any
  mighty-metropolis: ! '>=1.0.1'
  speedy-slice: ! '>=0.1.2'
  mwc-probability: ! '>=1.0.1'
  primitive: -any
all-versions:
- '0.1.0.0'
- '0.1.0.1'
author: Jared Tobin
latest: '0.1.0.1'
description-type: haddock
description: ! 'DIY Markov Chains.


  Build composite Markov transition operators from existing ones for fun and

  profit.


  A useful strategy is to hedge one''s sampling risk by occasionally

  interleaving a computationally-expensive transition (such as a gradient-based

  algorithm like Hamiltonian Monte Carlo or NUTS) with cheap Metropolis

  transitions.


  > transition = frequency [

  >     (9, metropolis 1.0)

  >   , (1, hamiltonian 0.05 20)

  >   ]


  Alternatively: sample consecutively using the same algorithm, but over a

  range of different proposal distributions.


  > transition = concatAllT [

  >     slice 0.5

  >   , slice 1.0

  >   , slice 2.0

  >   ]


  Or just mix and match and see what happens!


  > transition =

  >   sampleT

  >     (sampleT (metropolis 0.5) (slice 0.1))

  >     (sampleT (hamiltonian 0.01 20) (metropolis 2.0))


  Check the test suite for example usage.'
license-name: MIT
