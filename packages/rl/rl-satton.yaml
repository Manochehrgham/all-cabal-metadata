homepage: https://github.com/grwlf/rl
changelog-type: ''
hash: 1cee905a72f88fd738748fa4332d05e579483b3ca7720c01a2e2fbcd9742961e
test-bench-deps: {}
maintainer: grrwlf@gmail.com
synopsis: Collection of Reinforcement Learning algorithms
changelog: ''
basic-deps:
  MonadRandom: -any
  mersenne-random-pure64: -any
  stm: -any
  base: ! '>=4.8 && <5'
  time: -any
  unordered-containers: -any
  text: -any
  rl-satton: -any
  monad-loops: -any
  filepath: -any
  process: -any
  parsec: -any
  containers: -any
  lens: -any
  mtl: -any
  hashable: -any
  pretty-show: -any
  transformers: -any
  random: -any
  template-haskell: -any
  directory: -any
all-versions:
- '0.1.0'
- '0.1.1'
- '0.1.2'
- '0.1.2.1'
- '0.1.2.2'
author: Sergey Mironov
latest: '0.1.2.2'
description-type: haddock
description: ! 'rl-satton provides implementation of algorithms, described in the

  ''Reinforcement Learing: An Introduction'' book by Richard S. Satton and Andrew

  G. Barto. In particular, TD(0), TD(lambda), Q-learing are implemented.

  Code readability was placed above performance.

  Usage examples are provided in the ./examples folder.'
license-name: BSD3
